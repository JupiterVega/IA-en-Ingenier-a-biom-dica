{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelo creado con la finalidad de encontrar secunecias de ADN que distingan entre 3 especies distintas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Librerías\n",
    "\n",
    "Las librerías utilizadas son:  \n",
    "\n",
    "- **Torch**:  \n",
    "  Se utiliza como base para la construcción del modelo. Su función es la de construir y entrenar redes neuronales.  \n",
    "\n",
    "- **Torch-geometric**:  \n",
    "  Da herramientas para la manipulación de datos, así como generar los grafos.  \n",
    "\n",
    "- **Random**:  \n",
    "  Permite generar números random y, a su vez, también nos permite utilizar funciones con algunos valores random.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv, global_mean_pool\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    " **with open(\"/home/crakerool/datasets/chimpanzee.txt\", \"r\") as file:**  \n",
    "**with open()**: Permite acceder/abrir un archivo, y este se cerrará automáticamente al finalizar la operación.  \n",
    "**Ruta**: Explica dónde se encuentra el archivo en cuestión.  \n",
    "**r**: Esto indica que el archivo solo se puede acceder en modo lectura, sin permitir la modificación.  \n",
    "**as file**: Esto indica que se está asignando el archivo a la variable **file**, lo que nos permitirá interactuar con el archivo más adelante.  \n",
    "\n",
    "**chimpanzee_sequences = [line.strip() for line in file if line.strip()]**  \n",
    " **variable =**: Asigna lo que esté dentro de esta expresión a una variable.  \n",
    " **[line.strip() for line in file]**:  \n",
    " **line.strip()**: Elimina los espacios vacíos al inicio y al final de la línea. También incluye la eliminación de saltos de línea representados como **\\n**.  \n",
    " **for line in file**: Indica que se realizará la acción en cada línea del archivo.  \n",
    "**if line.strip()**: Condicional que indica que solo se procesarán las líneas que no estén vacías.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar las secuencias desde los archivos FASTA y asignar etiquetas\n",
    "with open(\"/home/crakerool/datasets/chimpanzee.txt\", \"r\") as file:\n",
    "    chimpanzee_sequences = [line.strip() for line in file if line.strip()]\n",
    "with open(\"/home/crakerool/datasets/dog.txt\", \"r\") as file:\n",
    "    dog_sequences = [line.strip() for line in file if line.strip()]\n",
    "with open(\"/home/crakerool/datasets/human.txt\", \"r\") as file:\n",
    "    human_sequences = [line.strip() for line in file if line.strip()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parte del codigo que indica que el el codigo se cargo correctamente por medio de una condicional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que se hayan cargado secuencias\n",
    "if not chimpanzee_sequences:\n",
    "    raise ValueError(\"No se encontraron secuencias en el archivo chimpanzee.txt\")\n",
    "if not dog_sequences:\n",
    "    raise ValueError(\"No se encontraron secuencias en el archivo dog.txt\")\n",
    "if not human_sequences:\n",
    "    raise ValueError(\"No se encontraron secuencias en el archivo human.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**min_count = min(len(chimpanzee_sequences), len(dog_sequences), len(human_sequences))**  \n",
    "**min()**: Toma el valor más pequeño dentro de los proporcionados.  \n",
    "**len()**: Lee la cantidad de secuencias dentro del archivo.  \n",
    "Toma la mínima cantidad de secuencias como un valor de la variable **min_count**.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir la cantidad mínima de secuencias entre todas las clases para balancear el dataset\n",
    "min_count = min(len(chimpanzee_sequences), len(dog_sequences), len(human_sequences))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**variable = random.sample(secuencia_variable, min_count)**    \n",
    "**random.sample(poblacion, z)**: Esto toma **z** como valores aleatorios de la variable **población**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Submuestreo: reducir cada clase a la misma cantidad de secuencias que la clase minoritaria\n",
    "balanced_chimpanzee_sequences = random.sample(chimpanzee_sequences, min_count)\n",
    "balanced_dog_sequences = random.sample(dog_sequences, min_count)\n",
    "balanced_human_sequences = random.sample(human_sequences, min_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**variable = [z] * min_count**  \n",
    "**z**: La lista que se cree tendrá el valor **z**.  \n",
    "Lo que se añadirá dependerá de cuántos valores existan en **min_count**.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear las etiquetas correspondientes\n",
    "balanced_chimpanzee_labels = [0] * min_count\n",
    "balanced_dog_labels = [1] * min_count\n",
    "balanced_human_labels = [2] * min_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suma las distintas variables con sus respetivas cosas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combinar las secuencias y etiquetas balanceadas\n",
    "balanced_sequences = balanced_chimpanzee_sequences + balanced_dog_sequences + balanced_human_sequences\n",
    "balanced_labels = balanced_chimpanzee_labels + balanced_dog_labels + balanced_human_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**combined = list(zip(balanced_sequences, balanced_labels))**  \n",
    "**list**: Indica que se está tratando con listas y seguirá en formato de listas.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**combined = list(zip(balanced_sequences, balanced_labels))**  \n",
    "**combined**: Asigna una nueva variable que contiene los elementos combinados de dos listas.  \n",
    "**zip()**: Combina dos o más listas, creando pares (tuplas) donde cada elemento de una lista se empareja con el correspondiente de la otra lista.  \n",
    "**list()**: Convierte el resultado de **zip()** en una lista para que sea manipulable.\n",
    "\n",
    "**random.shuffle(combined)**  \n",
    "Reordena aleatoriamente los elementos de la lista proporcionada, esto de la variable **combined**\n",
    "\n",
    "**balanced_sequences, balanced_labels = zip(combined)**  \n",
    "Separa las listas en dos distintas sin perder sus conexiones.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mezclar las secuencias y etiquetas para que estén en un orden aleatorio\n",
    "combined = list(zip(balanced_sequences, balanced_labels))\n",
    "random.shuffle(combined)\n",
    "balanced_sequences, balanced_labels = zip(*combined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def encode_sequence(sequence)**  \n",
    "**def**: Define una función con el nombre especificado.  \n",
    "**encode**: Es el nombre de la función.  \n",
    "**()**: Dentro de los paréntesis se toma la variable que representa lo que será definido.\n",
    "\n",
    "**encoding = {'A': 0, 'T': 1, 'C': 2, 'G': 3}**  \n",
    "**encoding**: Variable que convierte los parámetros a sus respectivos valores numéricos.\n",
    "\n",
    "**return [encoding[base] for base in sequence if base in encoding]**    \n",
    "**[encoding[base] for base in sequence]**: Utiliza una comprensión de listas para procesar cada carácter (base) de la secuencia.  \n",
    "**for base in sequence**: Itera sobre cada base en la secuencia.  \n",
    "**encoding[base]**: Usa el diccionario **encoding** para obtener el valor numérico asociado a la base.  \n",
    "**if base in encoding**: Filtra las bases, asegurándose de que solo se procesen las que están en el diccionario \n",
    "**encoding**. Si la secuencia contiene caracteres no válidos (como espacios o letras diferentes), estos serán ignorados.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Codificar las secuencias como vectores numéricos\n",
    "def encode_sequence(sequence):\n",
    "    encoding = {'A': 0, 'T': 1, 'C': 2, 'G': 3}\n",
    "    return [encoding[base] for base in sequence if base in encoding]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def sequence_to_graph(sequence)**\n",
    "Se crea una nueva función de Python sobre la \"base\" de secuencia, es decir, se usa la secuencia como parámetro de entrada para actuar sobre ella.\n",
    "\n",
    "**x = torch.tensor(sequence, dtype=torch.float).view(-1, 1)**\n",
    "**torch.tensor(sequence)**: Convierte la secuencia numérica en un tensor de PyTorch para que sea compatible con modelos basados en PyTorch.  \n",
    "**dtype=torch.float**: Especifica que los valores serán de tipo flotante.  \n",
    "**.view(-1, 1)**: Cambia la forma (dimensiones) del tensor para que cada número sea un nodo con un solo atributo.  \n",
    "**-1**: Ajusta automáticamente el tamaño de la primera dimensión (número de nodos), lo cual significa que las listas tendrán una única forma específica, por ejemplo:  \n",
    "[0,  \n",
    "1,  \n",
    "2,  \n",
    "3].\n",
    "\n",
    "**1**: Especifica que cada nodo tendrá un único atributo (el valor del nucleótido).\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**edge_index = []**  \n",
    "Crea una lista vacía que almacenará las conexiones (bordes) entre los nodos.\n",
    " \n",
    "**for i in range(len(sequence) - 1)**  \n",
    "Itera sobre cada índice de la secuencia, excepto el último, porque los bordes conectan nodos consecutivos.\n",
    "\n",
    "**edge_index.append([i, i + 1])**  \n",
    "Agrega un borde dirigido desde el nodo **i** al nodo **i + 1**.\n",
    "\n",
    "**edge_index.append([i + 1, i])**  \n",
    "Agrega un borde dirigido desde el nodo **i + 1** al nodo **i** (haciendo la conexión bidireccional).\n",
    "\n",
    "**edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()**  \n",
    "**torch.tensor(edge_index, dtype=torch.long)**: Convierte la lista **edge_index** en un tensor de tipo entero largo (**long**), requerido para representar índices de nodos en PyTorch.  \n",
    "**.t()**: Transpone el tensor para que los bordes estén en el formato correcto, donde cada columna representa un borde (**[nodo_origen, nodo_destino]**).  \n",
    "**.contiguous()**: Asegura que el tensor sea continuo en memoria, lo cual es necesario para operaciones eficientes en PyTorch.   \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**return Data(x=x, edge_index=edge_index)**    \n",
    "crea el grafo "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir una secuencia codificada en un grafo\n",
    "def sequence_to_graph(sequence):\n",
    "    x = torch.tensor(sequence, dtype=torch.float).view(-1, 1)  # Nodos con un solo atributo (el valor del nucleótido)\n",
    "    edge_index = []\n",
    "    for i in range(len(sequence) - 1):\n",
    "        edge_index.append([i, i + 1])\n",
    "        edge_index.append([i + 1, i])\n",
    "    edge_index = torch.tensor(edge_index, dtype=torch.long).t().contiguous()\n",
    "    return Data(x=x, edge_index=edge_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "  **graph_list = []**\n",
    "Crea una lista vacía para almacenar los grafos generados.\n",
    "\n",
    "\n",
    "\n",
    "  **for i, seq_record in enumerate(balanced_sequences)**\n",
    "Itera sobre las secuencias balanceadas junto con sus índices.\n",
    "\n",
    "\n",
    "\n",
    "  **encoded_sequence = encode_sequence(seq_record)**\n",
    "Codifica cada secuencia en una lista numérica.\n",
    "\n",
    "\n",
    "\n",
    "  **if len(encoded_sequence) == 0**\n",
    "Omite secuencias vacías.\n",
    "\n",
    "\n",
    "\n",
    "  **graph = sequence_to_graph(encoded_sequence)**\n",
    "Convierte la secuencia codificada en un grafo.\n",
    "\n",
    "\n",
    "\n",
    "  **graph.y = balanced_labels[i]**\n",
    "Asigna la etiqueta correspondiente (**balanced_labels[i]**) al grafo.\n",
    "\n",
    "\n",
    "\n",
    "  **graph_list.append(graph)**\n",
    "Agrega el grafo procesado a la lista.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear los grafos a partir de las secuencias balanceadas\n",
    "graph_list = []\n",
    "for i, seq_record in enumerate(balanced_sequences):\n",
    "    encoded_sequence = encode_sequence(seq_record)\n",
    "    if len(encoded_sequence) == 0:\n",
    "        continue  # Omitir secuencias vacías\n",
    "    graph = sequence_to_graph(encoded_sequence)\n",
    "    graph.y = torch.tensor([balanced_labels[i]], dtype=torch.long)  # Asignar la etiqueta correspondiente al organismo\n",
    "    graph_list.append(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verificar que se hayan creado grafos\n",
    "if len(graph_list) == 0:\n",
    "    raise ValueError(\"No se pudieron crear grafos a partir de las secuencias proporcionadas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**class ImprovedGNNModel(torch.nn.Module)**  \n",
    "Declara una clase que hereda de **torch.nn.Module**, el estándar para modelos en PyTorch. Modelo utilizado al momento de hacer GNN.\n",
    "\n",
    "**def __init__(self, num_classes)**  \n",
    "Define los componentes en la función **__init__**.\n",
    "\n",
    "**self.conv1 = GCNConv(1, 32)**\n",
    "**self.conv2 = GCNConv(32, 64)**\n",
    "**self.conv3 = GCNConv(64, 128)**\n",
    "**GCNConv**: Implementa una convolución para grafos usando **torch-geometric**. La entrada de cada capa es el número de características de los nodos en la capa anterior. La salida de cada capa es el número de características aprendidas.\n",
    "  - **Primera capa (conv1)**: Toma 1 característica por nodo (por ejemplo, el valor numérico del nucleótido). Produce 32 características por nodo.\n",
    "  - **Segunda capa (conv2)**: Toma 32 características y produce 64 características.\n",
    "  - **Tercera capa (conv3)**: Toma 64 características y produce 128 características.\n",
    "\n",
    "**self.dropout = torch.nn.Dropout(p=0.5)**\n",
    "**Dropout**: Apaga aleatoriamente el 50% (**p=0.5**) de las neuronas durante el entrenamiento.\n",
    "\n",
    "**self.lin = torch.nn.Linear(128, num_classes)**\n",
    "**torch.nn.Linear**: Toma las 128 características por grafo producidas por las capas convolucionales. Genera una salida de tamaño igual a **num_classes** (una predicción para cada clase).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**def forward(self, data)**  \n",
    "Define el modelo.\n",
    "\n",
    "**x, edge_index = data.x, data.edge_index**  \n",
    "Extrae las características de los nodos (**x**) y las conexiones entre ellos (**edge_index**) desde el objeto **data**.\n",
    "\n",
    "**x = F.relu(self.conv1(x, edge_index))**  \n",
    "**Primera capa**: Aplica la convolución **conv1** para generar características por nodo. Dependiendo de la capa, la cantidad será diferente (32 en este caso).  \n",
    "**F.relu**: Aplica la función de activación **ReLU**, que introduce no linealidad al modelo.\n",
    "\n",
    "**x = self.dropout(x)**  \n",
    "**Dropout**: Apaga algunas características de forma aleatoria, mejorando la generalización.\n",
    "\n",
    "**x = F.relu(self.conv3(x, edge_index))**  \n",
    "Similar a lo anterior, pero aplicado en la **tercera capa**.\n",
    "\n",
    "**x = global_mean_pool(x, data.batch)**  \n",
    "**global_mean_pool**: Reduce las características de todos los nodos en un único vector para cada grafo.  \n",
    "**data.batch**: Agrupa nodos del mismo grafo para calcular un promedio por grafo.\n",
    "\n",
    "**x = self.lin(x)**  \n",
    "Pasa el vector del grafo por la capa lineal para producir predicciones de tamaño **num_classes**.\n",
    "\n",
    "**return F.log_softmax(x, dim=-1)**  \n",
    "**F.log_softmax**: Convierte las salidas en probabilidades logarítmicas, que son útiles para clasificación multi-clase.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImprovedGNNModel(torch.nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(ImprovedGNNModel, self).__init__()\n",
    "        self.conv1 = GCNConv(1, 32)  # Incrementar el número de características\n",
    "        self.conv2 = GCNConv(32, 64)\n",
    "        self.conv3 = GCNConv(64, 128)  # Añadir una tercera capa de convolución\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)  # Dropout para regularización\n",
    "        self.lin = torch.nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = F.relu(self.conv1(x, edge_index))\n",
    "        x = F.relu(self.conv2(x, edge_index))\n",
    "        x = self.dropout(x)  # Aplicar dropout después de la segunda capa\n",
    "        x = F.relu(self.conv3(x, edge_index))\n",
    "        x = global_mean_pool(x, data.batch)  # Pooling global para obtener una representación del grafo completo\n",
    "        x = self.lin(x)\n",
    "        return F.log_softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**torch.device**\n",
    "Determina si el modelo usará **GPU (cuda)** o **CPU**, dependiendo de la disponibilidad.\n",
    "\n",
    "**num_classes**\n",
    "Calcula el número de clases únicas para clasificar los datos.\n",
    "\n",
    "**ImprovedGNNModel**\n",
    "Instancia el modelo GNN configurado con el número correcto de clases y lo mueve al dispositivo seleccionado.\n",
    "\n",
    "**torch.optim.Adam**\n",
    "Optimizador que ajusta los parámetros del modelo durante el entrenamiento con una tasa de aprendizaje específica.\n",
    "\n",
    "**DataLoader**\n",
    "Organiza y prepara los datos para ser procesados en lotes (**batch**) durante el entrenamiento, con mezcla aleatoria si se requiere.\n",
    "\n",
    "**model.train()**\n",
    "Configura el modelo en modo de entrenamiento (activa **dropout** y otras características).\n",
    "\n",
    "**optimizer.zero_grad()**\n",
    "Limpia gradientes acumulados de iteraciones previas.\n",
    "\n",
    "**model(data)**\n",
    "Genera predicciones del modelo para los datos actuales.\n",
    "\n",
    "**F.nll_loss**\n",
    "Calcula la pérdida comparando las predicciones con las etiquetas verdaderas.\n",
    "\n",
    "**loss.backward()**\n",
    "Calcula los gradientes de los parámetros del modelo respecto a la pérdida.\n",
    "\n",
    "**optimizer.step()**\n",
    "Ajusta los parámetros del modelo usando los gradientes calculados.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/crakerool/miniconda3/envs/gnn_env/lib/python3.10/site-packages/torch_geometric/deprecation.py:26: UserWarning: 'data.DataLoader' is deprecated, use 'loader.DataLoader' instead\n",
      "  warnings.warn(out)\n"
     ]
    }
   ],
   "source": [
    "# Preparar el entrenamiento\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = len(set(balanced_labels))  # Número de clases, correspondiente al número de organismos\n",
    "model = ImprovedGNNModel(num_classes).to(device)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "loader = DataLoader(graph_list, batch_size=16, shuffle=True)\n",
    "\n",
    "# Entrenar el modelo\n",
    "def train():\n",
    "    model.train()\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        out = model(data)\n",
    "        loss = F.nll_loss(out, data.y)\n",
    "        loss.backward()\n",
    "        optimizer.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ciclo de entrenamiento (for epoch in range(1, 500))**\n",
    "Ejecuta el proceso de entrenamiento por 500 iteraciones o épocas. Cada época representa una pasada completa sobre los datos.\n",
    "\n",
    "**Entrenamiento del modelo (train())**\n",
    "Llama a la función de entrenamiento definida previamente, que ajusta los parámetros del modelo en función de los datos y las etiquetas.\n",
    "\n",
    "**Progreso del entrenamiento (if epoch % 10 == 0)**\n",
    "Imprime un mensaje cada 10 épocas para indicar el progreso del entrenamiento.\n",
    "\n",
    "Al completar todas las épocas, muestra un mensaje que confirma que el proceso ha terminado.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 completed.\n",
      "Epoch 20 completed.\n",
      "Epoch 30 completed.\n",
      "Epoch 40 completed.\n",
      "Epoch 50 completed.\n",
      "Epoch 60 completed.\n",
      "Epoch 70 completed.\n",
      "Epoch 80 completed.\n",
      "Epoch 90 completed.\n",
      "Epoch 100 completed.\n",
      "Epoch 110 completed.\n",
      "Epoch 120 completed.\n",
      "Epoch 130 completed.\n",
      "Epoch 140 completed.\n",
      "Epoch 150 completed.\n",
      "Epoch 160 completed.\n",
      "Epoch 170 completed.\n",
      "Epoch 180 completed.\n",
      "Epoch 190 completed.\n",
      "Epoch 200 completed.\n",
      "Epoch 210 completed.\n",
      "Epoch 220 completed.\n",
      "Epoch 230 completed.\n",
      "Epoch 240 completed.\n",
      "Epoch 250 completed.\n",
      "Epoch 260 completed.\n",
      "Epoch 270 completed.\n",
      "Epoch 280 completed.\n",
      "Epoch 290 completed.\n",
      "Epoch 300 completed.\n",
      "Epoch 310 completed.\n",
      "Epoch 320 completed.\n",
      "Epoch 330 completed.\n",
      "Epoch 340 completed.\n",
      "Epoch 350 completed.\n",
      "Epoch 360 completed.\n",
      "Epoch 370 completed.\n",
      "Epoch 380 completed.\n",
      "Epoch 390 completed.\n",
      "Epoch 400 completed.\n",
      "Epoch 410 completed.\n",
      "Epoch 420 completed.\n",
      "Epoch 430 completed.\n",
      "Epoch 440 completed.\n",
      "Epoch 450 completed.\n",
      "Epoch 460 completed.\n",
      "Epoch 470 completed.\n",
      "Epoch 480 completed.\n",
      "Epoch 490 completed.\n",
      "Entrenamiento completado.\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo (opcional, agregar función de evaluación)\n",
    "for epoch in range(1, 500):\n",
    "    train()\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch} completed.\")\n",
    "\n",
    "print(\"Entrenamiento completado.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resultados\n",
    "Al observar los resultados que obtenemos, se observa que a diferencia de antes que dava 2 constantemente ahora genera una variante de esto lo que indica un avanze.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precisión en el conjunto de entrenamiento: 37.04%\n",
      "Secuencia real: [0, 2, 0, 2, 1, 1, 2, 0, 2, 0, 2, 0, 0, 1, 1, 1], Predicción del modelo: [2, 0, 2, 1, 2, 0, 2, 0, 2, 0, 0, 1, 2, 0, 1, 2]\n",
      "Secuencia real: [0, 0, 1, 2, 1, 0, 1, 1, 0, 1, 2, 0, 2, 2, 0, 0], Predicción del modelo: [0, 1, 2, 2, 0, 0, 1, 1, 2, 0, 0, 1, 0, 2, 0, 0]\n",
      "Secuencia real: [2, 0, 2, 1, 2, 1, 0, 1, 2, 1, 2, 1, 2, 1, 0, 2], Predicción del modelo: [1, 0, 2, 2, 2, 2, 2, 0, 1, 2, 2, 0, 2, 2, 0, 0]\n",
      "Secuencia real: [1, 2, 2, 0, 1, 1, 1, 0, 1, 2, 2, 2, 1, 2, 2, 1], Predicción del modelo: [0, 0, 0, 0, 0, 0, 2, 0, 2, 2, 2, 0, 1, 0, 1, 1]\n",
      "Secuencia real: [1, 0, 1, 2, 0, 1, 2, 0, 2, 1, 1, 0, 2, 0, 1, 1], Predicción del modelo: [2, 0, 0, 2, 0, 2, 1, 2, 2, 1, 1, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "# Evaluar el modelo y mostrar algunos resultados\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        out = model(data)\n",
    "        pred = out.argmax(dim=1)  # Predicción de la clase con mayor probabilidad\n",
    "        correct += (pred == data.y).sum().item()\n",
    "        total += data.num_graphs\n",
    "\n",
    "    accuracy = correct / total\n",
    "    print(f'Precisión en el conjunto de entrenamiento: {accuracy * 100:.2f}%')\n",
    "\n",
    "# Mostrar algunas predicciones de ejemplo\n",
    "for i, data in enumerate(loader):\n",
    "    if i >= 5:  # Mostrar solo 5 ejemplos\n",
    "        break\n",
    "    data = data.to(device)\n",
    "    out = model(data)\n",
    "    pred = out.argmax(dim=1)\n",
    "    print(f\"Secuencia real: {data.y.tolist()}, Predicción del modelo: {pred.tolist()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gnn_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
